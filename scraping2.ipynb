{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fccc6e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing C:/algorithm/br_example_constitution.html\n"
     ]
    }
   ],
   "source": [
    "%%writefile C:/algorithm/br_example_constitution.html\n",
    "<!doctype html>\n",
    "<html>\n",
    "  <head>\n",
    "    <meta charset=\"utf-8\">\n",
    "    <title>줄 바꿈 테스트 예제</title>\n",
    "  </head>\n",
    "  <body>\n",
    "  <p id=\"title\"><b>대한민국헌법</b></p>\n",
    "  <p id=\"content\">제1조 <br/>①대한민국은 민주공화국이다.<br/>②대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.</p>\n",
    "  <p id=\"content\">제2조 <br/>①대한민국의 국민이 되는 요건은 법률로 정한다.<br/>②국가는 법률이 정하는 바에 의하여 재외국민을 보호할 의무를 진다.</p>\n",
    "  </body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ec20e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대한민국헌법\n",
      "제1조 ①대한민국은 민주공화국이다.②대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.\n",
      "제2조 ①대한민국의 국민이 되는 요건은 법률로 정한다.②국가는 법률이 정하는 바에 의하여 재외국민을 보호할 의무를 진다.\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "f= open('C:/algorithm/br_example_constitution.html', encoding = 'utf-8')\n",
    "\n",
    "html_source = f.read()\n",
    "f.close()\n",
    "\n",
    "soup = BeautifulSoup(html_source, 'lxml')\n",
    "\n",
    "title = soup.find('p', {'id':'title'})\n",
    "contents = soup.find_all('p', {'id':'content'})\n",
    "\n",
    "print(title.get_text())\n",
    "for content in contents:\n",
    "    print(content.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad0756d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> 태그 p로 찾은 요소\n",
      "<p id=\"content\">제 1조 <br/>1대한민국은 민주공화국이다.<br/>2대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다</p>\n",
      "--> 결과에서 태그 br로 찾은 요소: <br/>\n",
      "--> 태그 br을 개행문자로 바꾼 결과\n",
      "<p id=\"content\">제 1조 \n",
      "1대한민국은 민주공화국이다.<br/>2대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다</p>\n"
     ]
    }
   ],
   "source": [
    "html1 = '<p id = \"content\">제 1조 <br/>1대한민국은 민주공화국이다.<br/>2대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다</p>'\n",
    "\n",
    "soup1 = BeautifulSoup(html1, 'lxml')\n",
    "\n",
    "print(\"--> 태그 p로 찾은 요소\")\n",
    "content1 = soup1.find('p', {'id':'content'})\n",
    "print(content1)\n",
    "\n",
    "br_content = content1.find('br')\n",
    "print('--> 결과에서 태그 br로 찾은 요소:', br_content)\n",
    "\n",
    "br_content.replace_with('\\n')\n",
    "print('--> 태그 br을 개행문자로 바꾼 결과')\n",
    "print(content1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e985b8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p id=\"content\">제1조 \n",
      "①대한민국은 민주공화국이다.\n",
      "②대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다.</p>\n"
     ]
    }
   ],
   "source": [
    "soup2 = BeautifulSoup(html1, 'lxml')\n",
    "content2 = soup.find('p', {'id':'content'})\n",
    "\n",
    "br_contents = content2.find_all('br')\n",
    "for br_content in br_contents:\n",
    "    br_content.replace_with('\\n')\n",
    "print(content2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb713c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_newline(soup_html):\n",
    "    br_to_newlines = soup_html.find_all('br')\n",
    "    for br_to_newline in br_to_newlines:\n",
    "        br_to_newline.replace_with('\\n')\n",
    "    return soup_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d671f848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제 1조 \n",
      "1대한민국은 민주공화국이다.\n",
      "2대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다\n"
     ]
    }
   ],
   "source": [
    "soup2 = BeautifulSoup(html1,'lxml')\n",
    "content2 = soup2.find('p', {'id':'content'})\n",
    "content3 = replace_newline(content2)\n",
    "print(content3.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52cb245e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대한민국헌법 \n",
      "\n",
      "제1조 \n",
      "①대한민국은 민주공화국이다.\n",
      "②대한민국의 주권은 국민에게 있고, 모든 권력은 국민으로부터 나온다. \n",
      "\n",
      "제2조 \n",
      "①대한민국의 국민이 되는 요건은 법률로 정한다.\n",
      "②국가는 법률이 정하는 바에 의하여 재외국민을 보호할 의무를 진다. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(html_source, 'lxml')\n",
    "\n",
    "title = soup.find('p', {'id':'title'})\n",
    "contents = soup.find_all('p', {'id':'content'})\n",
    "\n",
    "print(title.get_text(), '\\n')\n",
    "\n",
    "for content in contents:\n",
    "    content1 = replace_newline(content)\n",
    "    print(content1.get_text(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "362bb9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"http://www.alexa.com/topsites/countries/KR\"\n",
    "\n",
    "html_website_ranking = requests.get(url).text\n",
    "soup_website_ranking = BeautifulSoup(html_website_ranking, 'lxml')\n",
    "\n",
    "website_ranking = soup_website_ranking.select('p a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6ad588e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"https://support.alexa.com/hc/en-us/articles/200444340\" target=\"_blank\">this explanation</a>,\n",
       " <a href=\"/siteinfo/google.com\">Google.com</a>,\n",
       " <a href=\"/siteinfo/naver.com\">Naver.com</a>,\n",
       " <a href=\"/siteinfo/youtube.com\">Youtube.com</a>,\n",
       " <a href=\"/siteinfo/daum.net\">Daum.net</a>,\n",
       " <a href=\"/siteinfo/tistory.com\">Tistory.com</a>,\n",
       " <a href=\"/siteinfo/kakao.com\">Kakao.com</a>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "website_ranking[0:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6655fff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Google.com'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "website_ranking[1].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1b4e0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "website_ranking_address = [website_ranking_element.get_text() for website_ranking_element in website_ranking[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13f8bcff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Google.com',\n",
       " 'Naver.com',\n",
       " 'Youtube.com',\n",
       " 'Daum.net',\n",
       " 'Tistory.com',\n",
       " 'Kakao.com']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "website_ranking_address[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "340fa020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Top sites in South korea]\n",
      "1: Google.com\n",
      "2: Naver.com\n",
      "3: Youtube.com\n",
      "4: Daum.net\n",
      "5: Tistory.com\n",
      "6: Kakao.com\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"http://www.alexa.com/topsites/countries/KR\"\n",
    "\n",
    "html_website_ranking = requests.get(url).text\n",
    "soup_website_ranking = BeautifulSoup(html_website_ranking, 'lxml')\n",
    "\n",
    "website_ranking = soup_website_ranking.select('p a')\n",
    "website_ranking_address = [website_ranking_element.get_text() for website_ranking_element in website_ranking[1:]]\n",
    "\n",
    "print(\"[Top sites in South korea]\")\n",
    "for k in range(6):\n",
    "    print(\"{0}: {1}\".format(k+1, website_ranking_address[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c950a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Google.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naver.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Youtube.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Daum.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tistory.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Kakao.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       website\n",
       "1   Google.com\n",
       "2    Naver.com\n",
       "3  Youtube.com\n",
       "4     Daum.net\n",
       "5  Tistory.com\n",
       "6    Kakao.com"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "website_ranking_dick = {'website': website_ranking_address}\n",
    "df = pd.DataFrame(website_ranking_dick, columns={'website'}, index = range(1, len(website_ranking_address)+1))\n",
    "df[0:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7b61c9",
   "metadata": {},
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://www.python.org/static/img/python-logo.png'\n",
    "html_image = requests.get(url)\n",
    "html_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0d2a36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python-logo.png'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "image_file_name = os.path.basename(url)\n",
    "image_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1e75d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'C:/algorithm/download'\n",
    "\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b01dfca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/algorithm/download\\\\python-logo.png'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = os.path.join(folder, image_file_name)\n",
    "image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ed39269",
   "metadata": {},
   "outputs": [],
   "source": [
    "imageFile = open(image_path, 'wb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "55ea8458",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 1000000\n",
    "for chunk in html_image.iter_content(chunk_size):\n",
    "    imageFile.write(chunk)\n",
    "imageFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ccd0ab28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['python-logo.png']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f0a6e725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "url = 'https://www.python.org/static/img/python-logo.png'\n",
    "html_image = requests.get(url)\n",
    "image_file_name = os.path.basename(url)\n",
    "folder = 'C:algorithm/download'\n",
    "\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "\n",
    "image_path = os.path.join(folder, image_file_name)\n",
    "\n",
    "imageFile = open(image_path, 'wb')\n",
    "\n",
    "chunk_size = 1000000\n",
    "for chunk in html_image.iter_content(chunk_size):\n",
    "    imageFile.write(chunk)\n",
    "imageFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a219a6d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<img alt=\"Reshot\" height=\"33\" src=\"https://www.reshot.com/build/reshot-logo--mark-cc49363ac3f7876f854286af4266ead51a7ff9e0fa12f30677c9e758d43dd0d1.svg\" title=\"Reshot\" width=\"46\"/>,\n",
       " <img alt=\"\" class=\"photos-item-card__image\" height=\"2448\" loading=\"lazy\" src=\"https://res.cloudinary.com/twenty20/private_images/t_reshot-400/v1521838685/photosp/bae96789-a5ab-4471-b54f-9686ace09e33/bae96789-a5ab-4471-b54f-9686ace09e33.jpg\" width=\"2448\"/>,\n",
       " <img alt=\"Back off!\" class=\"photos-item-card__image\" height=\"2361\" loading=\"lazy\" src=\"https://res.cloudinary.com/twenty20/private_images/t_reshot-400/v1597098233/photosp/a44357c5-b1c3-41ef-9a65-7a4937b06a44/a44357c5-b1c3-41ef-9a65-7a4937b06a44.jpg\" width=\"3148\"/>,\n",
       " <img alt=\"Orphans\" class=\"photos-item-card__image\" height=\"3375\" loading=\"lazy\" src=\"https://res.cloudinary.com/twenty20/private_images/t_reshot-400/v1617578418/photosp/34fd9c70-8996-4706-a0f1-113231ed3eee/34fd9c70-8996-4706-a0f1-113231ed3eee.jpg\" width=\"3375\"/>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "URL = 'https://reshot.com/search/animal'\n",
    "\n",
    "html_reshot_image = requests.get(URL).text\n",
    "soup_reshot_image = BeautifulSoup(html_reshot_image, 'lxml')\n",
    "reshot_image_elements = soup_reshot_image.select('a img')\n",
    "reshot_image_elements[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0fb9f51f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://res.cloudinary.com/twenty20/private_images/t_reshot-400/v1521838685/photosp/bae96789-a5ab-4471-b54f-9686ace09e33/bae96789-a5ab-4471-b54f-9686ace09e33.jpg'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshot_image_url = reshot_image_elements[1].get('src')\n",
    "reshot_image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5aa5ddd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_image = requests.get(reshot_image_url)\n",
    "\n",
    "folder = 'C:/algorithm/download'\n",
    "\n",
    "imageFile = open(os.path.join(folder, os.path.basename(reshot_image_url)), 'wb')\n",
    "\n",
    "chunk_size = 1000000\n",
    "for chunk in html_image.iter_content(chunk_size):\n",
    "    imageFile.write(chunk)\n",
    "imageFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a5d94380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 파일명: 'reshot-logo--mark-cc49363ac3f7876f854286af4266ead51a7ff9e0fa12f30677c9e758d43dd0d1.svg'. 내려받기 완료!\n",
      "이미지 파일명: 'bae96789-a5ab-4471-b54f-9686ace09e33.jpg'. 내려받기 완료!\n",
      "이미지 파일명: 'a44357c5-b1c3-41ef-9a65-7a4937b06a44.jpg'. 내려받기 완료!\n",
      "이미지 파일명: '34fd9c70-8996-4706-a0f1-113231ed3eee.jpg'. 내려받기 완료!\n",
      "이미지 파일명: 'dbd9fa3b-238b-47b1-8e20-c05400cbe921.jpg'. 내려받기 완료!\n",
      "이미지 파일명: '737d192f-ba38-4a71-9bb9-9d40b45d0263.jpg'. 내려받기 완료!\n",
      "이미지 파일명: 'c3c3604d-36eb-4f8a-9768-cebc0749d5a5.jpg'. 내려받기 완료!\n",
      "=================\n",
      "선택한 모든 이미지 내려받기 완료!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "def get_image_url(url):\n",
    "    html_image_url = requests.get(url).text\n",
    "    soup_image_url = BeautifulSoup(html_image_url, 'lxml')\n",
    "    image_elements = soup_image_url.select('img')\n",
    "    if(image_elements != None):\n",
    "        image_urls = []\n",
    "        for image_element in image_elements:\n",
    "            image_urls.append(image_element.get('src'))\n",
    "        return image_urls\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def download_image(img_folder, img_url):\n",
    "    if(img_url != None):\n",
    "        html_image = requests.get(img_url)\n",
    "        imageFile = open(os.path.join(img_folder, os.path.basename(img_url)), 'wb')\n",
    "        \n",
    "        chunk_size = 1000000\n",
    "        for chunk in html_image.iter_content(chunk_size):\n",
    "            imageFile.write(chunk)\n",
    "            imageFile.close()\n",
    "            \n",
    "           \n",
    "        print(\"이미지 파일명: '{0}'. 내려받기 완료!\".format(os.path.basename(img_url)))\n",
    "    else:\n",
    "        print(\"내려받을 이미지가 없습니다.\")\n",
    "              \n",
    "reshot_url = 'https://www.reshot.com/search/animal'\n",
    "figure_folder = 'C:/algorithm/download'\n",
    "              \n",
    "reshot_image_urls = get_image_url(reshot_url)\n",
    "              \n",
    "num_of_download_image = 7\n",
    "              \n",
    "for k in range(num_of_download_image):\n",
    "    download_image(figure_folder, reshot_image_urls[k])\n",
    "print(\"=================\")\n",
    "print(\"선택한 모든 이미지 내려받기 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eef9347",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
